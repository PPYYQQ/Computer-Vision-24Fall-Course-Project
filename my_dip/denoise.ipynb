{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_depth):\n",
    "        super(UNet, self).__init__()\n",
    "        # 编码器部分\n",
    "        self.encoder1 = self.conv_block(input_depth, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        \n",
    "        # 解码器部分\n",
    "        self.up_conv1 = self.up_conv(1024, 512)\n",
    "        self.decoder1 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.up_conv2 = self.up_conv(512, 256)\n",
    "        self.decoder2 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.up_conv3 = self.up_conv(256, 128)\n",
    "        self.decoder3 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.up_conv4 = self.up_conv(128, 64)\n",
    "        self.decoder4 = self.conv_block(128, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)  # 输出通道数从 1 改为 3\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def up_conv(self, in_channels, out_channels):\n",
    "        # 使用 ConvTranspose2d 进行上采样\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码器\n",
    "        x1 = self.encoder1(x)\n",
    "        p1 = self.pool1(x1)\n",
    "\n",
    "        x2 = self.encoder2(p1)\n",
    "        p2 = self.pool2(x2)\n",
    "\n",
    "        x3 = self.encoder3(p2)\n",
    "        p3 = self.pool3(x3)\n",
    "\n",
    "        x4 = self.encoder4(p3)\n",
    "        p4 = self.pool4(x4)\n",
    "\n",
    "        x5 = self.bottleneck(p4)\n",
    "\n",
    "        # 解码器\n",
    "        d1 = self.up_conv1(x5)\n",
    "        d1 = torch.cat([d1, x4], dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "\n",
    "        d2 = self.up_conv2(d1)\n",
    "        d2 = torch.cat([d2, x3], dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "\n",
    "        d3 = self.up_conv3(d2)\n",
    "        d3 = torch.cat([d3, x2], dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "\n",
    "        d4 = self.up_conv4(d3)\n",
    "        d4 = torch.cat([d4, x1], dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "\n",
    "        out = self.final_conv(d4)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 加载图像并添加噪声\n",
    "def load_image(image_path, size=(256, 256)):\n",
    "    img = Image.open(image_path)  # 移除 .convert('L')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = transform(img).unsqueeze(0)  # 添加 batch 维度\n",
    "    return img\n",
    "\n",
    "def add_noise(img, noise_factor=0.1):\n",
    "    noisy_img = img + noise_factor * torch.randn(*img.shape)\n",
    "    return torch.clamp(noisy_img, 0., 1.)\n",
    "\n",
    "# 展示图像\n",
    "def show_images(original, noisy, denoised):\n",
    "    # 将张量转换为 numpy 数组，并移除批次维度\n",
    "    original = original.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    noisy = noisy.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    denoised = denoised.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # 由于 Matplotlib 的 imshow 函数期望图像值在 [0,1] 或 [0,255]，需要确保图像数据在 [0,1] 范围内\n",
    "    original = np.clip(original, 0, 1)\n",
    "    noisy = np.clip(noisy, 0, 1)\n",
    "    denoised = np.clip(denoised, 0, 1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(original)\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(noisy)\n",
    "    axs[1].set_title('Noisy Image')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(denoised)\n",
    "    axs[2].set_title('Denoised Image')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "def generate_gaussian_noise(input_depth, spatial_size, var=1./10):\n",
    "    \"\"\"\n",
    "    Generates a Gaussian noise tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_depth: The number of channels in the tensor\n",
    "    - spatial_size: The spatial dimensions of the tensor (height, width)\n",
    "    - var: The variance factor of the noise\n",
    "    \n",
    "    Returns:\n",
    "    - A PyTorch tensor filled with Gaussian noise\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(spatial_size, int):\n",
    "        spatial_size = (spatial_size, spatial_size)\n",
    "    \n",
    "    shape = (1, input_depth, spatial_size[0], spatial_size[1])\n",
    "    noise = torch.randn(shape) * var\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "\n",
    "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
    "\n",
    "input_depth = 32\n",
    "from utils import count_parameters\n",
    "\n",
    "net_input = generate_gaussian_noise(input_depth=input_depth, spatial_size=256)\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "\n",
    "net = UNet(input_depth=input_depth).to(device)\n",
    "\n",
    "print(f\"Model Parameters: {count_parameters(net)}\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# Load and prepare the image\n",
    "# image_path = './data/denoising/F16_GT.png'\n",
    "image_path = './data/denoising/snail.jpg'\n",
    "\n",
    "original_img = load_image(image_path)  # Returns tensor of shape [1, 1, 256, 256]\n",
    "noisy_img = add_noise(original_img).to(device)\n",
    "\n",
    "# Training loop\n",
    "num_steps = 1000\n",
    "for step in tqdm(range(num_steps)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "\n",
    "    net_input = net_input.to(device)\n",
    "    output = net(net_input)\n",
    "    # print(output.shape)\n",
    "    # print(noisy_img.shape)\n",
    "    loss = criterion(output, noisy_img)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # psrn_noisy = compare_psnr(img_noisy_np, out.detach().cpu().numpy()[0]) \n",
    "    # psrn_gt    = compare_psnr(img_np, out.detach().cpu().numpy()[0]) \n",
    "    # psrn_gt_sm = compare_psnr(img_np, out_avg.detach().cpu().numpy()[0]) \n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(f\"Step [{step+1}/{num_steps}], Loss: {loss.item():.4f}\")\n",
    "        show_images(original_img, noisy_img, output.detach())\n",
    "\n",
    "# Show results\n",
    "denoised_img = output.detach()\n",
    "show_images(original_img, noisy_img, denoised_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './F16_GT.png'  # 使用本地路径\n",
    "original_img = load_image(image_path)\n",
    "noisy_img = add_noise(original_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10000\n",
    "for step in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(noisy_img)\n",
    "    loss = criterion(output, original_img)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(f'Step {step}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_img = net(noisy_img).detach()\n",
    "show_images(original_img, noisy_img, denoised_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
